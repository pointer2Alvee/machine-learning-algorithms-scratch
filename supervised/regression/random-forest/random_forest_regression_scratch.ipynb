{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "737e2245",
   "metadata": {},
   "source": [
    "<b>Random-Forest-Regression - Scratch</b> <br>\n",
    "<i>Implementing Random Forest Regression using only NumPy, step-by-step. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96def8f7",
   "metadata": {},
   "source": [
    "<b>requirements</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619f7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:- pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69f5fe",
   "metadata": {},
   "source": [
    "<b>imports</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2316ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     x0   x1      x2    x3        x4        y\n",
      "0   800  0.0  0.3048  71.3  0.002663  126.201\n",
      "1  1000  0.0  0.3048  71.3  0.002663  125.201\n",
      "2  1250  0.0  0.3048  71.3  0.002663  125.951\n",
      "3  1600  0.0  0.3048  71.3  0.002663  127.591\n",
      "4  2000  0.0  0.3048  71.3  0.002663  127.461\n",
      "The Decision Tree: \n",
      "X_0 <= 3150.0 ? 7.132048702017748\n",
      " left:X_4 <= 0.0337792 ? 3.590330569067664\n",
      "  left:X_3 <= 55.5 ? 1.17898999813184\n",
      "    left:X_4 <= 0.00251435 ? 1.614396721819876\n",
      "        left:128.9919833333333\n",
      "        right:125.90953579676673\n",
      "    right:X_1 <= 15.4 ? 2.2342245360792994\n",
      "        left:129.39160280373832\n",
      "        right:123.80422222222222\n",
      "  right:X_0 <= 1250.0 ? 9.970884020498868\n",
      "    left:X_4 <= 0.0483159 ? 6.35527515982486\n",
      "        left:124.38024528301887\n",
      "        right:118.30039999999998\n",
      "    right:X_3 <= 39.6 ? 5.036286657241031\n",
      "        left:113.58091666666667\n",
      "        right:118.07284615384616\n",
      " right:X_4 <= 0.00146332 ? 29.08299210506528\n",
      "  left:X_0 <= 8000.0 ? 11.886497073996964\n",
      "    left:X_2 <= 0.0508 ? 7.608945827689519\n",
      "        left:134.04247500000002\n",
      "        right:127.33581818181818\n",
      "    right:X_4 <= 0.00076193 ? 10.6229193224008\n",
      "        left:128.94078571428574\n",
      "        right:122.40768750000001\n",
      "  right:X_4 <= 0.0229028 ? 5.638575922510643\n",
      "    left:X_0 <= 6300.0 ? 5.985051045988914\n",
      "        left:120.04740816326529\n",
      "        right:114.67370491803278\n",
      "    right:X_4 <= 0.0368233 ? 8.638744793046438\n",
      "        left:113.83169565217393\n",
      "        right:107.6395833333333\n",
      "root mean squared error: 4.851358097184457\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from decision_tree_regression import DecisionTreeRegressor  # Importing your Decision Tree Regressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac970ad7",
   "metadata": {},
   "source": [
    "<b>(1) DATA PRE-PROCESSING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f454045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dataset...\n",
      "Dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "# Read Raw Dataset \n",
    "print(\"Fetching dataset...\", flush=True)\n",
    "housing = fetch_california_housing()\n",
    "print(\"Dataset loaded!\", flush=True)\n",
    "\n",
    "\n",
    "# Feature-Matrix (X) & Dependent-Variable(y)\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# Data-Splitting \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "# Custom Dataset :-\n",
    "# X, y = datasets.make_regression(n_samples=150, n_features=1, noise=20, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=24)\n",
    "\n",
    "# Data Pre-Processing\n",
    "# Normalize (if needed)\n",
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad1bdc",
   "metadata": {},
   "source": [
    "<b>(2) ML ALGORITHM - SCRATCH</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e943cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS \n",
    "# Providing each tree with a random subset of data (Bootstrap Sampling)\n",
    "def bootstrap_sample(X, y):\n",
    "    n_samples = X.shape[0]  # Number of samples\n",
    "    idxs = np.random.choice(n_samples, size=n_samples, replace=True)  # Sampling with replacement\n",
    "    return X[idxs], y[idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80864b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST REGRESSOR CLASS\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_trees=100, min_samples_split=2, max_depth=2, n_feats=None):\n",
    "        \"\"\"\n",
    "        Initializes the Random Forest Regressor.\n",
    "        \n",
    "        Parameters:\n",
    "            n_trees : (int) Number of decision trees in the forest.\n",
    "            min_samples_split : (int) Minimum samples required to split a node.\n",
    "            max_depth : (int) Maximum depth of each tree.\n",
    "            n_feats : (int) Number of features considered for splitting at each node (random subspace method).\n",
    "        \"\"\"\n",
    "        self.n_trees = n_trees\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.n_feats = n_feats\n",
    "        self.trees = []  # Stores all decision trees in the forest\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Trains the Random Forest Regressor model.\n",
    "        \n",
    "        Parameters:\n",
    "            X : (np.array) Feature matrix.\n",
    "            y : (np.array) Target variable.\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            tree = DecisionTreeRegressor(min_samples_split=self.min_samples_split, max_depth=self.max_depth)\n",
    "            X_sample, y_sample = bootstrap_sample(X, y)\n",
    "            tree.fit(X_sample, y_sample.reshape(-1, 1))  # Ensuring correct shape for training\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts values using the trained Random Forest Regressor.\n",
    "        \n",
    "        Parameters:\n",
    "            X : (np.array) Feature matrix.\n",
    "            \n",
    "        Returns:\n",
    "            np.array : Predicted values (average of all trees' outputs).\n",
    "        \"\"\"\n",
    "        # Get predictions from all trees\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        \n",
    "        # Transpose to align predictions for averaging\n",
    "        tree_preds = np.swapaxes(tree_preds, 0, 1)  \n",
    "        \n",
    "        # Compute the mean prediction for each sample\n",
    "        y_pred = np.mean(tree_preds, axis=1)  # Average instead of majority voting\n",
    "        # here, RF clf used most_common_label(), but regression averages predictions from all trees:\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6186f364",
   "metadata": {},
   "source": [
    "<b>(3) MODEL TRAINING</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48929703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPLEMENTING RANDOM FOREST - REGRESSOR \n",
    "print(\"Initializing Random Forest Regressor...\", flush=True)\n",
    "reg = RandomForestRegressor(n_trees=3, max_depth=4)  # Start with 1 tree first\n",
    "\n",
    "print(\"Training started...\", flush=True)\n",
    "reg.fit(X_train, y_train)\n",
    "print(\"Training completed!\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f690a9",
   "metadata": {},
   "source": [
    "<b>(4) PREDICTION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a80801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicting...\", flush=True)\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c104254",
   "metadata": {},
   "source": [
    "<b>(5) EVALUATION-VISUALIZATION</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf345156",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating RMSE...\", flush=True)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320bd5c",
   "metadata": {},
   "source": [
    "<b>CONCLUSION</b>\n",
    "- Randopm Forest using DT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
